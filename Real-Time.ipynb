{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition and Verification in a Real Time Video (Webcam)\n",
    "\n",
    "\n",
    "A video by definition is collection of frames. A frame is an image. So essentially if we can recognize faces in every frame of the video, we can recognize every face in the video. \n",
    "\n",
    "## About the Code \n",
    "\n",
    "```\n",
    "with open(\"face-labels-single.pickle\", 'rb') as f:\n",
    "```\n",
    "First we load in the dictionary with the list of encodings and labels for verification\n",
    "\n",
    "Next we read the frame we want to recognize into a variable and resize it to 480px(for faster processing). Then, we convert it\n",
    "to an RGB format.\n",
    "\n",
    "After that we retrieve the faces in the form of coordinates using ```face_recognition.face_locations()``` and since we no longer have only 1 image to process we cannot afford to use cnn as our model for face detection. Hence we use the relatively less accurate but still pretty good <b>hog</b>. However, if you have the resources and can run this on a GPU, go ahead and run it using  ```model=\"cnn\"```.\n",
    "The ```number_of_times_to_upsample``` parameter(optional) essentially tells the code to look for smaller faces(default is 1). Would recommend to let it be 1 as it often leads to false positives when you're trying to detect smaller faces. \n",
    "\n",
    "\n",
    "NOW, once we have all the encodings i.e all the faces detected we try and and match them with the known faces encodings\n",
    "\n",
    "### How we do this you ask?\n",
    "\n",
    "We compare the encoding from the image with known ones by calculating the <b>Euclidian Distance</b>\n",
    "\n",
    "Euclidean distance is the length of a straight line between two vectors in Euclidean space. i.e. \n",
    "\n",
    "<img src=\"http://mathworld.wolfram.com/images/equations/Distance/NumberedEquation3.gif\">\n",
    "\n",
    "Once we compare them we classify them as match or not for all of the encodings through the following code\n",
    "\n",
    "```\n",
    "matches = face_recognition.compare_faces(data[\"encodings\"],\n",
    "        encoding,tolerance=0.45)\n",
    "```\n",
    "        \n",
    "The ``` tolerance ``` acts as the threshold for comparison , if the Euclidiean distance is less than 0.45 then the encoding is classified as a match(True) else not a match(fals)\n",
    "\n",
    "Hence matches is a grid of size (known faces * encodings found in the image). Next we parse through the grid and find out which encoding has the maximum number of matches and classify that as our found face.\n",
    "\n",
    "Finally we take all the faces verfied and print them on the image.\n",
    "\n",
    "#### That's it folks! We have a Real-Time Face Recognizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition \n",
    "import cv2\n",
    "import pickle\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Trained Data via Pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# if you wish to run on a video instead of real-time simply replace the 0 with the path of the video in ''\n",
    "\n",
    "# Initialize some variables\n",
    "names = []\n",
    "process_this_frame = True\n",
    "\n",
    "# data is a dictionary loaded with two lists\n",
    "# first containing a list of all the encodings\n",
    "# second containing the corresponding labels\n",
    "\n",
    "\n",
    "with open(\"face-labels-cnn.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame-wise Detection and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    if ret == True:\n",
    "        #convert BGR to RGB\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #resizing to 480p for a decent frame rate and fast processing\n",
    "        #you can tweak it find the best fit\n",
    "        \n",
    "        rgb = imutils.resize(frame, width=480)\n",
    "        frame = imutils.resize(frame,width=480)\n",
    "        \n",
    "        #face detection and encoding        \n",
    "        \n",
    "        boxes = face_recognition.face_locations(rgb,model=\"hog\")\n",
    "        # boxes contains the coordinates of the face(s) in the frame\n",
    "        # boxes = list of (y,x+w,y+h,x) or (top,right,bottom,left)\n",
    "        \n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        \n",
    "        # encoding contains A list of 128-dimensional face encodings (one for each face in the image)\n",
    "        # encoding is essentially a list of 128 values representing the 128 hog features of the face\n",
    "        \n",
    "        if  not encodings is None and boxes!=[] : # checking if a face exists in the frame\n",
    "            name = \"Unknown\"\n",
    "            for encoding,box in zip(encodings,boxes):\n",
    "                # attempt to match each face in the input image to our known\n",
    "                top,right,bottom,left = box\n",
    "                frame = cv2.rectangle(frame, (left,top), (right, bottom), (255, 0, 0), 2) #rectange around the face\n",
    "                matches = face_recognition.compare_faces(data['encodings'],encoding,tolerance=0.45)\n",
    "                \n",
    "                # data[encoding] is a list of encodings from the trained data \n",
    "                # that we retrived from the pickle file\n",
    "                #  if two face descriptor vectors have a Euclidean\n",
    "                # distance(tolerance) between them less than 0.45 then they are from the same\n",
    "                # person, otherwise they are from different people.\n",
    "                # By default the tolerance is set to 0.6 but I personally found\n",
    "                # 0.45 to be more accurate for my dataset\n",
    "                \n",
    "                if True in matches : \n",
    "                    matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "                    counts = {}\n",
    "\n",
    "                    # loop over the matched indexes and maintain a count for\n",
    "                    # each recognized face face\n",
    "                    for i in matchedIdxs:\n",
    "                        name = data[\"names\"][i]\n",
    "                        counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "                # determine the recognized face with the largest number\n",
    "                # of votes (note: in the event of an unlikely tie Python\n",
    "                # will select first entry in the dictionary)\n",
    "                    name = max(counts, key=counts.get)\n",
    "                else :\n",
    "                    name = \"Unknown\"\n",
    "                y = top - 15 if top - 15 > 15 else top + 15\n",
    "                cv2.putText(frame, name, (left,y), cv2.FONT_HERSHEY_SIMPLEX, 1, 255, 2) #putting the name on the face\n",
    "                names.append(name)\n",
    "                #print(name)\n",
    "        cv2.imshow('Video', frame)\n",
    "    else: \n",
    "        break\n",
    "\n",
    "\n",
    "        # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
